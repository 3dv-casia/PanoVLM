# 两点确定二维直线

两点 $P_1(x_1,y_1)$ 和 $P_2(x_2,y_2)$ 确定直线 $l:y=kx+b$
$$
\left\{\begin{matrix}
k=\frac{y_1-y_2}{x_1-x_2}   \\
 b=y_1-kx_1\\
\end{matrix}\right.
$$

# 空间点到二维直线投影

已知直线方程为$l:y=kx+b$，直线外一点 $P(X,Y)$ 到直线的投影点为 $P'(X',Y')$

那么可以知道直线 $PP'$ 与 $l$ 垂直，那么直线 $PP'$ 的斜率为 $-\frac{1}{k}$, 因此可以得到
$$
\left \{
\begin{array}{c}
\frac{Y-Y'}{X-X'}=-\frac{1}{k} \\
Y'=kX'+b
\end{array}
\right. \quad \Longrightarrow \quad
\left \{
\begin{array}{c}
X'=\frac{k(Y-b)+X}{k^2+1} \\
Y'=kX'+b
\end{array}
\right. 
$$

# 两点确定三维直线

两点 $P_1(x_1,y_1,z_1)$ 和 $P_2(x_2,y_2,z_2)$ 确定的直线表达式为 
$$
\frac{x-x_1}{x_2-x_1}=\frac{y-y_1}{y_2-y_1}=\frac{z-z_1}{z_2-z_1}
$$

# 空间点到三维直线投影

### 第一种方式

假设直线的表达式为 $\frac{x-x_0}{n_x}=\frac{y-y_0}{n_y}=\frac{z-z_0}{n_z}$，空间点 $P(X,Y,Z)$ 到直线的投影点为 $P'(X',Y',Z')$

根据几何可知，向量 $PP'$ 与 直线的法向量 $n=(n_x,n_y,n_z)$ 垂直，也就是
$$
PP'*n=n_x(X-X')+n_y(Y-Y')+n_z(Z-Z')=0
$$
而且 $P'$ 在直线上，那么有 
$$
\frac{X'-x_0}{n_x}=\frac{Y'-y_0}{n_y}=\frac{Z'-z_0}{n_z}=k
$$
由此可以得到
$$
\left\{\begin{matrix}
 X'=kn_x+x_0\\
 Y'=kn_y+y_0\\
Z'=kn_z+z_0
\end{matrix}\right.
$$
把 $X' Y' Z'$ 的表达式带入第一个方程可以得到
$$
n_x(X-kn_x-x_0)+n_y(Y-kn_y-y_0)+n_z(Z-kn_z-z_0)=0 \\
k(n_x^2+n_y^2+n_z^2)=n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)\\
k=\frac{n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)}{n_x^2+n_y^2+n_z^2}
$$
得到 $k$ 后即可计算得到 $P'$坐标



如果直线是使用两个点来表达的，例如 $p_1=(x_1,y_1,z_1)^T,p_2=(x_2,y_2,z_2)^T$

那么同样可以用这两个点相减得到直线的方向向量，然后用以上步骤计算，结果为
$$
k=\frac{(x_2-x_1)(X-x_1)+(y_2-y_1)(Y-y_1)+(z_2-z_1)(Z-z_1)}{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2}
$$

### 第二种方式

直线表达式为 $\frac{x-x_0}{n_x}=\frac{y-y_0}{n_y}=\frac{z-z_0}{n_z}$，空间点 $P(X,Y,Z)$ 到直线的投影点为 $P'(X',Y',Z')$

设点 $A(x_0,y_0,z_0)$，那么可以把 $\overrightarrow{AP'} $ 看做是 $\overrightarrow{AP}$ 在直线的方向 $\vec{n}$ 上的投影，也就是说
$$
\overrightarrow{AP'}=\frac{\overrightarrow{AP}\cdot\vec{n}}{|\vec{n}|^2} \vec{n} \\
X'-x_0=\frac{n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)}{{n_x^2+n_y^2+n_z^2}}n_x \\
X'=\frac{n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)}{{n_x^2+n_y^2+n_z^2}}n_x  +x_0 \\
Y'=\frac{n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)}{{n_x^2+n_y^2+n_z^2}}n_x  +y_0 \\
Z'=\frac{n_x(X-x_0)+n_y(Y-y_0)+n_z(Z-z_0)}{{n_x^2+n_y^2+n_z^2}}n_x  +z_0 \\
$$
可以看到结果是一样的，但这种方法更好写成矩阵形式
$$
P'=\frac{(P-A)^T\vec n \vec n}{|\vec{n}|^2}+A
$$

# 点到三维直线距离

点 $P$ 到直线$\frac{x-x_0}{n_x}=\frac{y-y_0}{n_y}=\frac{z-z_0}{n_z}$ 的距离可以看做是把 $P$ 投影到直线上得到 $P'$，然后计算 $PP'$ 的长度

假设空间直线过点 $A(x_0,y_0,z_0)$ ，方向为 $\vec n=(n_x, n_y, n_z)$ 是单位向量，那么点 $P$ 到直线的距离写成矩阵乘法的形式就是
$$
\begin{align}
P-P'&=P-\left[(P-A)^T\vec n \vec n + A \right ] \\
&=P-A-(P-A)^T\vec n \vec n \\
&=P-A-\vec n^T (P-A)\vec n \\
&=P-A-\vec n\vec n^T (P-A) \\
&=(I-\vec n\vec n^T)(P-A)
\end{align}
$$
推导过程中 $(P-A)^T\vec n$ 是一个数，所以有 $(P-A)^T\vec n=\vec n^T(P-A)$

# 点到二维直线距离

假设直线的表达式为 $ax+by+c=0$，点 $P=(x_1,y_1)$，那么点到直线距离为
$$
d=\frac{ax_1+by_1+c}{\sqrt{a^2+b^2}}
$$
如果直线的形式为 $y=kx+b$，那么距离的表达式可以相应的改为
$$
d=\frac{kx_1-y_1+b}{\sqrt{k^2+1}}
$$

# 判断一个点是否为直线点

找到一个点及其最近邻的n个点，如果这n个点都在同一条直线上，那么它们肯定共面，使用下面的[判断平面的方法](#判断一个点是否为平面点)虽然能找到一个法向量，但约束不足。考虑使用PCA（主成分分析）。因为PCA就是对数据进行分析，找到m维数据中方差最大的那一个方向作为主成分，然后找到和之前的主成分正交的，方差第二大的方向作为第二个主成分，以此类推。所以对于属于同一直线的点，它们一定有一个方差特别大的主成分，而且第二个主成分方差会很小。

## 公式推导

使用PCA的第一步就是得到协方差矩阵S
$$
S=\frac{1}{N} \sum_{n=1}^{N}(x_n-\bar x)(x_n-\bar x)^T
$$
其中的$\bar x$是均值，这对应着代码中的

```c++
Eigen::Vector3d center(0, 0, 0);
for (int j = 0; j < 50; j++)
{
    Eigen::Vector3d tmp(points[j].x, points[j].y, points[j].z);
    center = center + tmp;
    nearCorners.push_back(tmp);
}
center = center / 50.0;

Eigen::Matrix3d covMat = Eigen::Matrix3d::Zero();
for (int j = 0; j < 50; j++)
{
    Eigen::Matrix<double, 3, 1> tmpZeroMean = nearCorners[j] - center;
    covMat = covMat + tmpZeroMean * tmpZeroMean.transpose();
}
```

对协方差矩阵进行特征分解，最大的特征值对应的就是第一个主成分，第二大的特征值就是第二个主成分。

- 如果所有点在同一直线上，那么第一个主成分远大于第二个主成分

- 如果不在同一直线上，两个主成分差异不大


对应的代码如下

```c++
Eigen::SelfAdjointEigenSolver<Eigen::Matrix3d> saes(covMat);
Eigen::Vector3d unit_direction = saes.eigenvectors().col(2);
// note Eigen library sort eigenvalues in increasing order
if (saes.eigenvalues()[2] > 3* saes.eigenvalues()[1])
{
    // these points can form a line
}

```

# 三点确定平面

假设三个点 $P_1(x_1,y_1,z_1)^T,P_2(x_2,y_2,z_2)^T, P_3(x_3,y_3,z_3)^T$

平面的表达式为 $ax+by+cz+d=0$

假设平面法向量为 $n=(n_x,n_y,n_z)$, 根据法向量的定义可以知道
$$
\begin{align}
 \hat n=&\overrightarrow{P_1P_2}\times\overrightarrow{P_1P_3}=\begin{bmatrix} x_1-x_2\\ y_1-y_2\\z_1-z_2\end{bmatrix}\times\begin{bmatrix} x_1-x_3\\ y_1-y_3\\z_1-z_3\end{bmatrix}=
\begin{vmatrix}
 i & j & k \\
 x_1-x_2 & y_1-y_2 & z_1-z_2 \\
  x_1-x_3 & y_1-y_3 & z_1-z_3
\end{vmatrix} \\ \\
=&\begin{bmatrix}(y_1-y_2)(z_1-z_3)-(z_1-z_2)(y_1-y_3) \\
(z_1-z_2)(x_1-x_3)-(x_1-x_2)(z_1-z_3) \\
(x_1-x_2)(y_1-y_3)-(y_1-y_2)(x_1-x_3)
\end{bmatrix} \\ \\
n=& \ normalize(\hat n)
\end{align}
$$
得到法向量后，平面可以用点法式来表达，也就是 $n_x(x-x_1)+n_y(y-y_1)+n_z(z-z_1)=0$
$$
a=n_x \quad b=n_y \quad c=n_z \quad d=-n_xx_1-n_yy_1-n_zz_1
$$


# 点到平面距离

点 $P(X,Y,Z)$ 到平面 $ax+by+cz+d=0$ 的距离为
$$
L=\left |\frac{aX+bY+cZ+d}{\sqrt{a^2+b^2+c^2}} \right |
$$

如果平面使用点法式来表达，也就是 $n_x(x-x_1)+n_y(y-y_1)+n_z(z-z_1)=0$

那么点$P(X,Y,Z)$ 到平面的距离为
$$
L=|\mathbf{n}^T(P-P_1)|
$$

其中的 $P_1=(x_1,y_1,z_1)$

# 点到平面投影

点 $P(X,Y,Z)$ 到平面 $ax+by+cz+d=0$ 的投影点为 $P'(X',Y',Z')$

先计算点 $P$ 到平面的距离 $L$，然后已知 $PP'$ 是和平面的法向量平行的，且 $\left \|PP' \right \|=L$。那么就可以得到
$$
P-P'=\pm L * (a,b,c)^T \quad \Longrightarrow \quad 
\left \{ \begin{matrix} P'=P+L(a,b,c)^T \\ P' = P-L(a,b,c)^T
\end{matrix}
\right .
$$
这两个结果中只有一个是正确的，因此还需要把算得的 $P'$ 带回平面方程中，看哪个符合

# 两平面夹角

两平面表达式为 $A_1x+B_1y+C_1z+D_1=0$ 和 $A_2x+B_2y+C_2z+D_2=0$

那么两平面的夹角与两个法向量之间的夹角是互补的，相加为180度。求出法向量的夹角即可得到平面夹角

又因为平面的夹角一般都定义为锐角，所以最终可以计算得到两平面的夹角 $\theta$ 为
$$
\theta = \arccos \left( \frac{\left|A_1A_2+B_1B_2+C_1C_2\right|}{\sqrt{A_1^2+B_1^2+C_1^2}\sqrt{A_2^2+B_2^2+C_2^2}} \right)
$$

# 两平面交线

两平面表达式为 $A_1x+B_1y+C_1z+D_1=0$ 和 $A_2x+B_2y+C_2z+D_2=0$

两平面的交线的方向是垂直于两个平面的法向量，因此直线的方向向量 $n_l=[A_1,B_1,C_1]^T\times[A_2,B_2,C_2]^T$

直线经过的点同时属于两个平面，因此可以把两个平面方程联立
$$
\left \{
\begin{array}{c} A_1x+B_1y+C_1z+D_1=0 \\  A_2x+B_2y+C_2z+D_2=0 \end{array}
\right .
$$
很明显可以观察到，这个方程是有无穷多解的，因为两个方程对应三个未知数。也很好理解，因为两个平面相交得到的是一条直线而不是一个点，所以肯定有无穷多解。而实际上只需要求出一个解就可以了，因此令 $z=1$，方程变为
$$
\left \{
\begin{array}{c} A_1x+B_1y=-C_1-D_1 \\  A_2x+B_2y=-C_2-D_2 \end{array}
\right . \quad \Longrightarrow \quad 
\begin{bmatrix} A_1 & B_1 \\ A_2 & B_2 \end{bmatrix}
\begin{bmatrix} x \\ y \end{bmatrix}=
\begin{bmatrix} -C_1-D_1 \\ -C_2-D_2 \end{bmatrix}
$$
可以直接通过矩阵乘法求出 $x,y$ 的值，然后再加上 $z=1$，就得到了平面交线经过的空间点

# 判断一个点是否为平面点

找到点$P$及其周围的$n$个近邻点，把这 $n$ 个点构成一个矩阵 $n$ 行3列的矩阵$A，b$是所有元素为-1的 $n$ 维列向量。求解$Ax=b$得到的$x$就是这 $n$ 个点构成的平面的法向量。*注意这个法向量不是单位向量*

然后依次让每个点与法向量进行点乘并加上 $\left\|x\right\|$ ，如果结果都接近于0，那么说明这 $n$ 个点确实在同一平面上。

## 公式推导

**为了称呼方便，把从原点出发，以某一个点为终点的向量称为“点向量”**

假设$n$个近邻点分别为
$$
P_1=[x_1,y_1,z_1]^T  P_2=[x_2,y_2,z_2]^T ... P_n=[x_n,y_n,z_n]^T
$$
那么矩阵$Ax=b$可以写为

$$
 \begin{bmatrix} P_1\\P_2\\...\\P_n \end{bmatrix}*\begin{bmatrix}n_1\\n_2\\n_3\end{bmatrix}= \begin{bmatrix}-1\\-1\\...\\-1\end{bmatrix}
$$
这个公式代表从原点出发，以每一个点为终点，得到$n$个点向量。这$n$个点向量和法向量点乘得到的结果都是-1。

根据点乘的几何意义可知，$a*b$ 表示$a$在$b$上的投影与$|b|$的乘积。

这就说明每个点向量在法向量方向上的投影都是相同的（假设投影长度为d），而且这些点向量的方向与法向量方向相反。只有在同一个平面上才能满足这个方程，所以这个方程求解出的是平面的法向量的**方向**。

根据几何可知，这$n$个向量在法向量方向上投影的长度就是平面与原点的距离，所以假设平面与原点的距离为$d$。又因为点乘的结果为-1，表示当前求出的$x$的模长为$1/d$。所以$d=1/||x||$。

其实这里令点乘结果都是1也是可以的，只是求出来的法向量的方向会是反向的。

之前的推导都是正向推导，也就是说如果$n$个点都满足在同一个平面上，就会有各种结论。然而实际上，几乎不可能真的出现n个点在同一平面上，因为会有噪声、误差等等影响，所以$Ax=b$ 得出的解实际上是一个最小二乘解，而不是一个解析解。这也就代表着无论这n个点是否真的在一个平面上，都能算出一个解$x$ 出来，所以要对这个解进行一下验证，看看这些点是否真的在同一个平面上。也就是以下这段代码

```c++
bool planeValid = true;
for (int j = 0; j < pointSearchSqDis.size(); j++)
   if(fabs(norm(0) * (points[j].x) +
           norm(1) * (points[j].y) +
           norm(2) * (points[j].z) + negative_OA_dot_norm) >0.05)          
    {
       planeValid = false;
       break;
    }
```

让每一个点都和法向量进行点乘，得到的结果是这个点构成的点向量在法向量方向的投影的长度$m$的相反数$-m$.这是因为法向量与这些点向量的方向是相反的，之前计算的时候b的每一项都是-1。

- 如果所有点真的都共面的话，那么点乘的结果就是平面到原点的距离$d$。也就是说每个点乘的结果都应该接近$-m$，那么就有$-m+d=0$。这里d就是代码中的`negative_OA_dot_norm`

- 如果不是所有点共面，也就是说有一些外点，那么点乘的结果-m+d会与0相去甚远

- 两种情况的截图如图所示
  <img src="C:\Users\TDT\Desktop\wby\相关推导\图片1.png" alt="图片1" style="zoom: 50%;" />

# 平面和直线相交

假设当前平面为$ax+by+cz+d=0$ 当前直线为 $\frac{x-x_0}{n_x}=\frac{y-y_0}{n_y}=\frac{z-z_0}{n_z}$，要计算平面和直线的交点。

首先把直线写成参数的形式，即
$$
x=x_0+tn_x\\
y=y_0+tn_y\\
z=z_0+tn_z
$$
这里的 $t$ 是未知数，确定了这个值就可以确定直线上唯一的一个点。又因为这个点在平面上，所以把参数形式带入平面方程可以得到
$$
a(x_0+tn_x)+b(y_0+tn_y)+c(z_0+tn_z)=0\\
ax_0+by_0+cz_0+t(an_x+bn_y+cn_z)=0\\
t=-\frac{ax_0+by_0+cz_0}{an_x+bn_y+cn_z}
$$
把算得的 $t$ 带回直线的参数方程即可得到平面与直线的交点。这里可以看出，分母是平面的法向量和直线的方向向量的内积，如果两个方向是垂直的，内积为0，则 $t=\infin$，此时直线和平面平行

# 矩阵和向量的范数

## 向量范数

1-范数：向量元素绝对值之和 $\left \| \mathbf x \right \|_1=\sum_{i=1}^N | x_i|$

2-范数：欧几里得(Euclid)范数 ，向量所有元素平方和再开方 $\left \| \mathbf x \right \|_2=\sqrt{ \sum_{i=1}^N  x_i^2}$

p-范数：向量所有元素的 $p$ 次方之和再开 $p$ 次方根 $\left \| \mathbf x \right \|_p=\left ( \sum_{i=1}^N |x_i|^p\right )^{\frac{1}{p}}$

无穷-范数：向量中所有元素绝对值的最大值 $\left \| \mathbf x \right \|_ \infin=\max|x_i|$

负无穷-范数：向量中所有元素绝对值的最小值 $\left \| \mathbf x \right \|_ {-\infin}=\min|x_i|$

## 矩阵范数

矩阵是 $m$ 行 $n$ 列的任意矩阵，$a_{ij}$ 代表第 $i$ 行 第$j$ 列的元素

1-范数：矩阵的列向量绝对值之和的最大值 $\left \| A \right \|_1=\max_{j=1,2,...,n} \left (\sum_{i=1}^m |a_{ij}|\right )$

2-范数：又叫谱范数，是 $A^TA$ 的最大特征值的平方根 $\left \| A \right \|_2=\sqrt \lambda_1$

无穷-范数：矩阵的行向量绝对值之和的最大值 $\left \| A \right \|_\infin=\max_{i=1,2,...,m} \left (\sum_{j=1}^n |a_{ij}|\right )$

F-范数：Frobenius范数，所有元素绝对值的平方和再开平方 $\left \| A \right \|_F=\sqrt{\sum_{i,j} |a_{ij}|^2} $

# 最小二乘法

## 基础理论

需要计算方程 $A\bf{x}=b$,其中$A$是样本组成的矩阵，$\bf x$是未知的系数，$\bf b$是观测结果

以3维的样本为例，假设采集了5个三维样本，那么就是
$$
A=\begin{bmatrix}
 a_{11} & a_{12} & a_{13} \\
 a_{21} & a_{22} & a_{23} \\
 a_{31} & a_{32} & a_{33} \\
 a_{41} & a_{42} & a_{43} \\
 a_{51} & a_{52} & a_{53} 
\end{bmatrix} \quad \mathbf{x}=
\begin{bmatrix}
    x_1 \\ x_2 \\ x_3
\end{bmatrix} \quad \mathbf{b}=
\begin{bmatrix}
    b_1 \\ b_2 \\ b_3 \\ b_4 \\ b_5
\end{bmatrix}
$$
为了得到最优的 $\mathbf{x}$ 就需要使用最小二乘法计算，也就是最小化误差和  
$$
\min (\mathbf{b}-A\mathbf{x})^T(\mathbf{b}-A\mathbf{x})=\min e^Te
$$
把优化项打开，可以得到  
$$
\begin{aligned}
&(\mathbf{b}-A\mathbf{x})^T(\mathbf{b}-A\mathbf{x}) \\
=&\mathbf{b}^T\mathbf{b}-\mathbf{b}^TA\mathbf{x}-\mathbf{x}^TA^T\mathbf{b}+\mathbf{x}^TA^TA\mathbf{x} \\
=&\mathbf{b}^T\mathbf{b}-2\mathbf{b}^TA\mathbf{x}+\mathbf{x}^TA^TA\mathbf{x}
\end{aligned}
$$
之后要计算 $e^Te$ 对 $\mathbf{x}$ 的导数，并令导数为零  
首先看第一项的 $\mathbf{b}^T\mathbf{b}$，由于其中不含有$\mathbf{x}$，因此其导数为0  
接着是第二项的 $\mathbf{b}^TA\mathbf{x}$，这是一个标量，标量对向量的导数是一个向量。举一个更简单的例子，比如向量 $m=(m_1,m_2,m_3)$ 是三维列向量，那么 $m^T\mathbf{x}$ 对 $\mathbf{x}$ 的导数为 
$$
\nabla_\mathbf{x}m^T\mathbf{x}= \begin{bmatrix}
\frac{\partial m^T\mathbf{x}}{\partial x_1} \\
\frac{\partial m^T\mathbf{x}}{\partial x_2} \\
\frac{\partial m^T\mathbf{x}}{\partial x_3}
\end{bmatrix}= \begin{bmatrix}
\frac{m_1x_1+m_2x_2+m_3x_3}{\partial x_1} \\
\frac{m_1x_1+m_2x_2+m_3x_3}{\partial x_2} \\
\frac{m_1x_1+m_2x_2+m_3x_3}{\partial x_3}
\end{bmatrix}=
\begin{bmatrix}
    m_1 \\ m_2 \\ m_3
\end{bmatrix}=m
$$
所以$\mathbf{b}^TA\mathbf{x}$ 对 $\mathbf{x}$的导数为 $A^T\mathbf{b}$ , 这是因为上面的公式使用的 $m$ 是一个列向量，而这里的 $\mathbf{b}^TA$ 是一个行向量
接着看第三项 $\mathbf{x}^TA^TA\mathbf{x}$，这同样是一个标量，因此对$\mathbf{x}$的导数为一个向量。同样举一个更简单的例子，比如矩阵 $M$ 是一个$3\times3$的矩阵，那么 $\mathbf{x}^TM\mathbf{x}$ 就是
$$
\mathbf{x}^TM\mathbf{x}=m_{11} x_{1}^{2}+m_{22} x_{2}^{2}+m_{33} x_{3}^{2}+2 m_{12} x_{1} x_{2}+2 m_{13} x_{1} x_{3}+2 m_{23} x_{2} x_{3}
$$
对 $\mathbf{x}$的导数为
$$
\nabla_\mathbf{x}\mathbf{x}^TM\mathbf{x} =
\begin{bmatrix}
 \frac{\partial \mathbf{x}^TM\mathbf{x}}{\partial x_1}\\
 \frac{\partial \mathbf{x}^TM\mathbf{x}}{\partial x_2}\\
\frac{\partial \mathbf{x}^TM\mathbf{x}}{\partial x_3}
\end{bmatrix}=
\begin{bmatrix}
 2m_{11}x_1+2m_{12}x_2+2m_{13}x_3\\
 2m_{22}x_2+2m_{12}x_1+2m_{23}x_3\\
2m_{33}x_3+2m_{13}x_1+2m_{23}x_2
\end{bmatrix}=2M\mathbf{x}
$$
所以 $e^Te$ 对 $\mathbf{x}$的导数为
$$
\nabla_\mathbf{x}e^Te =2A^TA\mathbf{x}-2A^T\mathbf{b}
$$
令导数为0，可以得到
$$
\begin{align}
2A^TA\mathbf{x}-2A^T\mathbf{b}&=0 \\
A^TA\mathbf{x}&=A^T\mathbf{b} \\
\mathbf{x}&=(A^TA)^{-1}A^T\mathbf{b}

\end{align}
$$

## 直接线性变换(DLT)求解绝对平移

这种方法要求已知绝对旋转以及相对平移的尺度和方向

这个方法对应于代码中的 `TranslationAveragingDLT()`,可以用来给其他方法设置初始位姿

为了方便表示，使用 $R_i,\ t_i$ 表示第 $i$ 张图像的全局位姿，也就是从世界坐标系到相机坐标系的变换；使用 $R_{ij}, \ t_{ij}$ 表示从第 $i$ 张图像到第 $j$ 张图像的旋转和平移。

在无噪声的理想情况下，所有图像的相对位姿和绝对位姿之间应该满足 $t_j-R_{ij}t_i-t_{ij}=0$. 在已知$R_{ij}, \ t_{ij}$ 的情况下，可以线性求解出 $t_i$. 具体方法如下：

假设当前有4个相机，有5个相对变换，那么就可以列出
$$
\begin{array}{c}
t_4-R_{14}t_1=t_{14} \\
t_4-R_{24}t_2=t_{24} \\
t_3-R_{23}t_2=t_{23} \\
t_2-R_{12}t_1=t_{12} \\
t_3-R_{13}t_1=t_{13}
\end{array}
$$
把这5个方程写成Ax=b的矩阵形式就是
$$
\begin{bmatrix}
 -R_{14} & 0 & 0 &  1 \\
 0 & -R_{24} & 0 &  1 \\
 0 & -R_{23} & 1 &  0 \\
 -R_{12} & 1 & 0 & 0  \\
 -R_{13}& 0 & 1 & 0 
\end{bmatrix} 
\begin{bmatrix} t_1\\t_2\\t_3\\t_4  \end{bmatrix} =
\begin{bmatrix} t_{14}\\t_{24}\\t_{23}\\t_{12} \\ t_{13} \end{bmatrix}
$$
注意，这里的 0 都是3x3的0矩阵，1都是3x3的单位阵。因此矩阵A的大小为15行12列，是一个很稀疏的矩阵。

在实际的程序编写中，需要把每一个元素都写出来。

# 三角化

## 全景图像三角化

把特征点变换到单位球上，得到 $P_s=[x,y,z]^T\quad x^2+y^2+z^2=1$

假设目前有 $n$ 张图像，空间点 ${X}$ 在这 $n$ 张图像上的单位球上的投影是 $\mathbf{p_1, p_2, \dots,p_n}$

从世界坐标系到这 $n$张图像的变换分别为 $R_1,t_1,R_2,t_2,...,R_n,t_n$， 也就是 $P_i=R_iP_w+t_i$

把 $X$ 变为其次坐标，可以得到 $[R_i|t_i]X=d_i\mathbf{p_i}$，其中 $d_i$ 就是 $X$ 在当前相机坐标系下的投影深度

用 $P_i=[R_i|t_i]$ 来表示，并把方程展开可以得到
$$
\begin{bmatrix}P_i^1X \\P_i^2X \\P_i^3X \\\end{bmatrix}=d_i
\begin{bmatrix}p_i^1\\p_i^2\\p_i^3 \end{bmatrix}
$$
其中的 $P_i^1\ 以及 \ p_i^1$ 就代表矩阵 $P_i$ 以及向量 $\mathbf{p_i}$ 的第一行，同理，上标的2，3就代表第二行和第三行。
方程中的 $X$ 和 $d_i$ 都是未知变量，为了简化表示方法，可以把相机坐标系下的点 $P_s=[x,y,z]^T$ 中最后一个维度变为1，也就是 $P_s'=[x/z,y/z,1]^T$  
在这种情况下，上述的等式就变为  
$$
\begin{bmatrix}P_i^1X \\ P_i^2X \\ P_i^3X\end{bmatrix}  = d_ip_i^3
\begin{bmatrix}p_i^1/p_i^3 \\ p_i^2/p_i^3 \\ 1\end{bmatrix} = \lambda_i
\begin{bmatrix}x_i \\ y_i \\ 1\end{bmatrix}
$$
那么可以列出三个方程 
$$
\left \{
\begin{matrix}
    P_i^1X = \lambda_i x_i \\
    P_i^2X = \lambda_i y_i \\
    P_i^3X = \lambda_i \ \ \ 
\end{matrix}
\right . \quad \Longrightarrow
\left \{
\begin{matrix}
    P_i^1X = P_i^3X x_i \\
    P_i^2X = P_i^3X y_i \\
\end{matrix}
\right . \quad \Longrightarrow
\left \{
\begin{matrix}
    (x_iP_i^3 - P_i^1)X = 0  \\
    (y_iP_i^3 - P_i^2)X = 0 \\
\end{matrix}
\right .
$$
每一个特征点可以提供两个等式约束，至少需要两个匹配的特征才可以解出结果。对于 $n$ 个匹配的特征，可以提供 $2n$ 个约束，写成矩阵形式为
$$
\begin{bmatrix}
    x_1P_1^3 - P_1^1 \\
    y_1P_1^3 - P_1^2 \\
    x_2P_2^3 - P_2^1 \\
    y_2P_2^3 - P_2^2 \\
    x_3P_3^3 - P_3^1 \\
    y_3P_3^3 - P_3^2 \\
    \vdots \\
    x_nP_n^3 - P_n^1 \\
    y_nP_n^3 - P_n^2 \\
\end{bmatrix}_{2n\times 4} X=
\begin{bmatrix}
    0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 0
\end{bmatrix}_{2n\times 1}
$$
这就是 $AX=0$ 的形式，可以通过求最小二乘解得到结果。也就是 $X$ 是 $A^TA$ 的最小特征值对应的特征向量

 


从另一个角度思考，相机坐标系下的点 $P_s=[x,y,z]^T$ 中最后一个维度不变成1，那么就可以得到
$$
\left \{
\begin{matrix}
    P_i^1X = d_i p_i^1  \\
    P_i^2X = d_i p_i^2  \\
    P_i^3X = d_i p_i^3 
\end{matrix}
\right .
$$
每张图像可以求得三个约束，写成矩阵形式就是
$$
\begin{bmatrix}
    P_i^1 & p_i^1 \\
    P_i^2 & p_i^2 \\
    P_i^3 & p_i^3 \\
\end{bmatrix}_{3\times 5}
\begin{bmatrix} X \\ d_i \end{bmatrix}_{5\times 1} = \mathbf{0}_{3\times 1}
$$
对于 $n$ 张图像就有 $3n$ 个约束，写成矩阵形式为
$$
\begin{bmatrix}
    P_1^1 & p_1^1 & 0 & 0 & \dots & 0 \\
    P_1^2 & p_1^2 & 0 & 0 & \dots & 0 \\
    P_1^3 & p_1^3 & 0 & 0 & \dots & 0 \\
    P_2^1 & 0 & p_2^1 & 0 & \dots & 0 \\
    P_2^2 & 0 & p_2^2 & 0 & \dots & 0 \\
    P_2^3 & 0 & p_2^3 & 0 & \dots & 0 \\
    P_3^1 & 0 & 0 & p_3^1 & \dots & 0 \\
    P_3^2 & 0 & 0 & p_3^2 & \dots & 0 \\
    P_3^3 & 0 & 0 & p_3^3 & \dots & 0 \\
    \vdots & \vdots& \vdots& \vdots& \vdots& \vdots \\
    P_n^1 & 0 & 0 & 0 & \dots & p_n^1 \\
    P_n^2 & 0 & 0 & 0 & \dots & p_n^2 \\
    P_n^3 & 0 & 0 & 0 & \dots & p_n^3 \\
\end{bmatrix}_{3n \times (4 + n)} 
\begin{bmatrix} X \\ d_1 \\ d_2 \\ d_3 \\ \vdots \\ d_n \end{bmatrix}_{(4+n)\times 1} = \mathbf{0}_{3n\times 1}
$$
这个方程仍然是 $AX=0$ 的形式，可以用最小二乘求解

# 对极几何

## 针孔模型对极几何

假设两张图像的内参分别为 $K_1, \ K_2$，把图像1当做世界坐标系，从图像1到图像2的变换为 $R,t$ 也就是 $P_2=RP_1+t$

对于世界坐标系下的一个点 $X$，它在两张图像上的成像分别为 $x_1,\ x_2$ 

根据针孔相机模型可以得到
$$
d_1x_1=KX \\
d_2x_2=K(RX+t)
$$
其中的 $d_1,\ d_2$ 是点 $X$ 的投影深度。将上述两个公式变换一下可以得到
$$
\left\{\begin{matrix}
 X=d_1K_1^{-1}x_1\\
 RX+t=d_2K_2^{-1}x_2
\end{matrix}\right.
$$
用 $\hat x_1 和 \hat x_2$ 代替 $K_1^{-1}x_1 以及\  K_2^{-1}x_2$ ，$\hat x_1 和\  \hat x_2$ 代表了归一化相机坐标系上的点，也就是在相机坐标系下 $z=1$ 平面上的点
$$
\left\{\begin{matrix}
 X=d_1\hat x_1\\
 RX+t=d_2\hat x_2
\end{matrix}\right.
\Longrightarrow  
d_1R\hat x_1+t=d_2\hat x_2
$$
在等式两侧同时乘以 $[t]_\times$ 可以得到， $[t]_\times$代表 $t$ 对应的反对称矩阵，用在向量叉乘上就是 $a\times b=[a]_\times b$
$$
d_1[t]_\times R\hat x_1+[t]_\times t=d_2[t]_\times \hat x_2
$$
由于 $[t]_\times t=0$ ，并在等式两侧同时乘以 $\hat x_2^T$
$$
d_1\hat x_2^T [t]_\times R\hat x_1=d_2\hat x_2^T [t]_\times \hat x_2
$$
由于 $x_2^T [t]_\times \hat x_2=0$ ，那么等式就变为了
$$
d_1\hat x_2^T [t]_\times R\hat x_1=0 \quad \Longrightarrow \quad \hat x_2^T E\hat x_1=0
$$

## 全景图像对极几何

假设两张图像是全景图像，图像上的点都可以变换到单位球上，也就是 $P_s=[x,y,z]^T\quad x^2+y^2+z^2=1$

把图像1当做世界坐标系，从图像1到图像2的变换为 $R,t$ 也就是 $P_2=RP_1+t$

对于世界坐标系下的一个点 $X$，它在两张图像的单位球上的投影的坐标分别为 $x_1,\ x_2$ 

那么可以得到
$$
\left\{\begin{matrix}
d_1x_1=X\\
d_2x_2=RX+t
\end{matrix}\right. \quad
\Longrightarrow \quad 
d_2x_2=d_1Rx_1+t
$$
其中的 $d_1,\ d_2$ 是点 $X$ 的投影深度。在等式两侧同时乘以 $[t]_\times$ 可以得到
$$
d_2[t]_\times x_2=d_1[t]_\times Rx_1
$$
在等式两侧同时乘以 $x_2^T$
$$
d_2x_2^T [t]_\times x_2=d_1x_2^T [t]_\times Rx_1
$$
由于 $x_2^T [t]_\times x_2=0$，那么等式就变为了
$$
x_2^T [t]_\times Rx_1=0 \quad \Longrightarrow \quad x_2^T Ex_1=0
$$

# 两视图几何

从图像1到世界坐标系的旋转和平移为 $R_{w1}, t_{w1}$, 从图像2到世界坐标系的旋转和平移为 $R_{w2},t_{w2}$ ，那么根据公式可以得到

图像1的光心 $C_1=t_{w1},\quad t_{1w}=-R_{1w}t_{w1}$ 

图像2的光心 $C_2=t_{w2},\quad t_{2w}=-R_{2w}t_{w2}$ 

两视图之间的相对变换可以表示为 

$R_{21}=R_{w2}^TR_{w1}=R_{2w}R_{w1} \quad t_{21}=R_{w2}^T(t_{w1}-t_{w2})=R_{2w}(t_{w1}-t_{w2})=t_{2w}-R_{21}t_{1w}$

$R_{12}=R_{w1}^TR_{w2}=R_{1w}R_{w2} \quad t_{12}=R_{w1}^T(t_{w2}-t_{w1})=R_{1w}(t_{w2}-t_{w1})=t_{1w}-R_{12}t_{2w}$

## 平面诱导的单应变换

对于两张图像上，如果某些点满足位于同一个空间平面上，那么两张图像上的点可以通过单应变换一一对应，也就是 $x_2=Hx_1$，其中的 $H$ 代表单应变换矩阵。一下为单应变换矩阵的推导过程。

假设空间中存在一个平面 $\pi$，其法向量为 $n$，并且过空间中一点 $X$。这里都假设图像1为世界坐标系，所以平面法向量和空间点都是世界坐标系下的坐标。

那么这个平面的方程可以表示为 $n^T(X-p)=0$ 。这里的 $p$ 代表着平面上的任意一点。把这个等式稍加变形即可得到
$$
n^TX=n^Tp \quad \Longrightarrow \quad \frac{n^Tp}{n^TX}=1
$$
图像1上的某个点 $x_1$ 和图像2上的某个点 $x_2$ 是对应的，且它们对应的空间点就在 $\pi$ 上，这个空间点用 $P$ 来表示，那么根据投影关系可以知道
$$
\lambda_1K_1^{-1}x_1 = P \\
\lambda_2K_2^{-1}x_2 = R_{21}P+t_{21}
$$
这里的 $\lambda_1,\lambda_2$ 是两个点的深度。第一个方程带入第二个可以得到
$$
\begin{array}{rl}
\lambda_2K_2^{-1}x_2 &= R_{21}\lambda_1K_1^{-1}x_1+t_{21}\times1 \\
&=R_{21}\lambda_1K_1^{-1}x_1+t_{21}\frac{n^TP}{n^TX} \\
&=R_{21}\lambda_1K_1^{-1}x_1+t_{21}\frac{n^T\lambda_1K_1^{-1}x_1}{n^TX} \\
&=\lambda_1\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}x_1 \\
x_2 &=\frac{\lambda_1}{\lambda_2}K_2\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}x_1
\end{array}
$$
同样的，单应矩阵不具备尺度，舍弃尺度即可得到 $H=K_2\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}$

这个单应矩阵就是PatchMatch MVS中进行投影的基础，给定了某个像素点的深度，那么就确定了这个点对应的空间点 $X$，在给定一个法向量，即可唯一确定单应矩阵。这个像素点周围的点就可以认为是在同一个平面上，也通过这个矩阵投影到其他图像上。

对于全景相机来说，单应矩阵也是同样的推导过程，差异在于全景相机没有内参，因此单应矩阵中没有 $K$ ，那么 $H=R_{21}+\frac{t_{21}n^T}{n^TX}$

要注意的一点是，全景相机下的 $x_1,x_2$ 不再是图像坐标，应该是像素点在单位球上的坐标。

## 单应变换的问题

如果当前的单应矩阵为 $H=K_2\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}$，那么图像1上的一点 $x_1$ 通过变换可以得到图像2上的一点 $x_2$ ，也就是
$$
\begin{align}
x_2&=K_2\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}x_1 \\
K_2^{-1}x_2&=\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )K_1^{-1}x_1 \\
v_2&=\left (R_{21}+\frac{t_{21}n^T}{n^TX}\right )v_1 \\
v_2&=R_{21}v_1+\frac{t_{21}n^Tv_1}{n^TX}
\end{align}
$$
这里的 $v_1,v_2$ 就是从光心到像素点的两条射线，一般称为 `view ray`. 

如果三维平面和 $v_1$ 是平行的，即 $n^Tv_1=0$ ，那么此时空间平面和 $v_1$ 没有交点，那么自然也无法在图像2上找到对应点 $x_2$。但实际上，在这种情况下，却有 $v_2=R_{21}v_1$ ，也就是说仍然能找到一个图像点与 $x_1$ 相对应，这很明显是不正确的。

# 旋转平均

使用 $R_{wi}$ 代表从第 $i$ 个相机位置到世界坐标系的变换，使用 $R_{ji}$ 代表从第 $i$ 个相机到第 $j$ 个相机的相对旋转，那么就有 $R_{ji}=R_{wj}^{-1}R_{wi}$

旋转平均的目标就是从相对旋转中计算得到绝对旋转，对于 $n$ 个相机，至少需要 $n-1$ 个相对旋转才能确定整体的绝对旋转。在实际问题中，一般会得到 $m$ 个相对旋转，而且 $m>>n$，因此这个问题是可以求解的。

由于在实际问题中，相对旋转的计算是存在误差的，所以只有在无噪声的情况下才能满足$R_{ji}=R_{wj}^{-1}R_{wi}$。因此，整个问题的求解目标是在有噪声的情况下通过相对旋转计算绝对旋转。写成优化函数就是
$$
{\arg \min} \sum_{ij}\rho(d(R_{ji},\ R_{wj}^{-1}R_{wi}))
$$
这里的 $d(R_{ji},\ R_{wj}^{-1}R_{wi})$ 代表两个旋转矩阵之间的差异，意思就是计算 $R_{ji}$ 和 $ R_{wj}^{-1}R_{wi}$之间的差异。 $\rho(*)$ 是一个鲁棒的核函数，用来降低外点的影响。

## 直接线性变换(DLT)求解绝对旋转

这种方法就是直接使用最小二乘法得到绝对旋转，由于图像对之间的相对旋转是有噪声的，有时候甚至有错误匹配，所以这种方法得到的结果肯定不好，但是可以当做一个初始值，用于其他的方法。

这里用来衡量旋转矩阵差异的方法就是两个矩阵相减，也就是 $d(R_{jw}, R_{ji}  R_{iw})=R_{jw} - R_{ji}  R_{iw}$ 。在无噪声的情况下，$R_{jw} - R_{ji}  R_{iw}=0$ 。可以看到这里是把 $R_{iw}和R_{jw}$ 分开了，没有让他们相乘，主要是为了方便后面写成矩阵 $AX=0$ 的形式。

矩阵 $A$ 是 $3m\times3n$ 的分块矩阵，每一个块是 $3\times 3$ 的小矩阵，为了方便叙述，下面所说的行列数都是以分块为基本单位的。

对于第 $k$ 个相对旋转，是从相机 $i$ 到相机 $j$ 的，那么 $A$ 的第 $k$ 行中第 $i$ 列元素是 $-R_{ji}$ , 第 $k$ 行中第 $j$ 列元素是 $I_{3\times 3}$ ,第 $k$ 行中其他元素都是0. 所以，$A$ 中每一行只有两列是非零的。

矩阵 $X$ 是 $3n\times 1$ 的分块矩阵，每一个块是 $3\times 3$ 的小矩阵，代表着每个相机的绝对旋转。

通过相对旋转构建出方程 $AX=0$后即可使用最小二乘法求解。

## 生成树（spanning tree）求解绝对旋转

通过对位姿图(pose graph) 遍历得到最大生成树，然后求解绝对旋转。这个方法是对pose graph上每一条边赋予一个权重，然后选定一个节点，从这个节点开始找到一颗最大生成树来遍历整个图。得到最大生成树之后，把根节点的绝对旋转设置为单位阵，然后根据最大生成树依次设置其他节点的绝对旋转。

这个方法不需要数学求解，但是需要设置权重，不同权重会产生不同的生成树，进而得到不同结果。因此也仅仅适合作为一个初始值，用于其他方法的优化。

## Robust Rotation Averaging - TPAMI 2018

这篇文章作者使用轴角(axis-angle)作为旋转矩阵之间的差异衡量标准，也就是说 $d(R_1,R_2)=\left \|\omega(R_2R_1^{-1})\right \|$。

为了和论文里的公式统一，下面改一下表示符号。 $R_i=R_{iw}$ 表示从世界坐标系到第 $i$ 个相机的旋转

那么整体的优化函数就可以写成以下形式
$$
\begin{array}{cl}
&{\arg \min} \sum_{ij}\rho(d(R_{ji}, R_jR_i^{-1})) \\
=&{\arg \min} \sum_{ij}\rho\left( \left \|\omega( R_j^{-1}R_{ji}R_i) \right \| \right)\\
=&{\arg \min} \sum_{ij}\rho\left( \left \|\omega(\Delta R_{ji}) \right \| \right)
\end{array}
$$
这里的 $\Delta R_{ji}$ 就代表着当前相机 $i,j$ 的绝对旋转和计算得到的相对旋转之间的差异。因此整个函数可以看作是找到最符合当前观测的全局旋转，也就是令全局旋转和相对旋转之间的差异最小。因为有着鲁棒核函数，这个优化整体是一个迭代的过程，在每一次迭代中，要找到一个最优的全局解使得当前的目标函数最小。

使用 $\Delta \mathbf R=\{\Delta R_1,\Delta R_2,\dots,\Delta R_n\}$ 代表当前迭代结束时找到的各个旋转矩阵相对于上一次迭代时的变化，那么本次迭代结束时旋转矩阵就可以表示为 $R_1=R_1'\Delta R_1$，这里的 $R_1'$是上一次迭代结束时的旋转矩阵。所以，每一次的迭代过程就是一个寻找旋转矩阵变化量的过程，这个变化量可以让目标函数变得更低。这种情况下，目标函数就可以表示为
$$
\begin{array}{cl}
&{\arg \min} \sum_{ij}\rho\left( \left \|\omega\left( (R_j\Delta R_j)^{-1}R_{ji}(R_i\Delta R_i) \right) \right \| \right)\\
=&{\arg \min} \sum_{ij}\rho\left( \left \|\omega\left( \Delta R_j^{-1}R_j^{-1}R_{ji}R_i\Delta R_i \right) \right \| \right)\\
=&{\arg \min} \sum_{ij}\rho\left( \left \|\omega\left( \Delta R_j^{-1}\Delta R_{ji}\Delta R_i \right) \right \| \right)\\
\end{array}
$$
在这里，把所有的旋转矩阵都用轴角来表示，这是因为最小化过程中需要求梯度，而旋转矩阵本身没办法求导数，需要使用轴角来代表旋转矩阵才行。所以优化目标可以表示为
$$
{\arg \min} \sum_{ij}\rho\left( \left \|\omega \left( R(-\Delta \omega_j)R(\Delta \omega_{ji})R(\Delta\omega_i) \right) \right \| \right) \\
=\arg \min\sum_{ij}\rho\left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)=\arg \min F(\Delta \Omega_{\mathcal V})
$$
这里的 $\mathbf r_{ij}(\Delta \Omega_{\mathcal V})=\omega \left( R(-\Delta \omega_j)R(\Delta \omega_{ji})R(\Delta\omega_i) \right)$ , 其中的 $\Delta \Omega_{\mathcal V}$ 是把所有的绝对旋转用轴角表示。写成这种形式是为了突出当前优化的参数就是全局旋转。为了最小化函数 $F(\Delta \Omega_{\mathcal V})$，就需要求它关于 $\Delta \Omega_{\mathcal V}$ 的梯度，结果为
$$
\begin{array}{cl}
\nabla F(\Delta \Omega_{\mathcal V})&=\sum_{ij}\nabla\rho\left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right) \\
&=\sum_{ij}\psi\left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right) \nabla \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)
\end{array}
$$
这里的$F(\Delta \Omega_{\mathcal V})$ 是一个复合函数，外层是函数 $\rho(*)$，内层是函数 $\left \| \mathbf r_{ij}(*)\right \|$。根据复合函数求导法则可以知道整体结果等于外层对内层的导数乘以内层对变量的导数。所以这里的 $\psi\left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)$ 就是外层对内层的求导结果。

令 $\phi \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)= \frac{ \psi\left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)}{\left\| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \|}$, 带入原等式可以得到
$$
\nabla F(\Delta \Omega_{\mathcal V})=\frac{1}{2}\sum_{ij} \phi \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)
2\left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \|\nabla \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right) \\
=\frac{1}{2}\sum_{ij} \phi \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)\nabla \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \|^2 \right)
$$
这一步可以进行如此变换是因为 $[f(x)]^2$ 的导数是 $2xf'(x)$，上面的等式就是把这个过程逆过来了。到了这一步，就可以令 $\nabla F(\Delta \Omega_{\mathcal V})=0$ 来求 $\Delta \Omega_{\mathcal V}$ 了。可以看出，目标函数中的 $\phi \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \| \right)$ 是一个权重，为了计算的效率，每一次迭代过程中，把这个权重设定为一个固定值，即 $\phi_{ij}=\phi \left( \left \| \mathbf r_{ij}(0) \right \| \right)$。也就是把旋转的增量设置为0，得到的误差用来计算权重。

那么整体函数就可以写为
$$
\sum_{ij} \phi_{ij}\nabla \left( \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \|^2 \right)=0 \\
$$
这个优化目标等价于（==我没想明白为什么等价==）
$$
\min \sum_{ij} \phi_{ij} \left \| \mathbf r_{ij}(\Delta \Omega_{\mathcal V}) \right \|^2 
$$
这个就是在每一次迭代过程中需要优化的目标函数。再经过一番推导之后，可以得到每次迭代的结果
$$
-\Phi A \Omega_{\mathcal V}=\Phi \Delta\Omega_{\delta} \\
-A^T\Phi A \Omega_{\mathcal V}=A^T\Phi \Delta\Omega_{\delta} \\
\Omega_{\mathcal V} =-\left ( A^T\Phi A\right )^{-1}A^T \Phi \Delta \Omega_{\delta}
$$
 这里的矩阵 $A$ 是一个 $3m \times 3n$ 的分块矩阵，每个小块要么是零矩阵，要么是正单位阵，要么是负单位阵。对于第 $k$ 个相对旋转，如果是关于相机 $i$ 和相机 $j$ 之间的，那么矩阵 $A$ 的第 $k$ 行的第$i$ 列就是 $I$，第  $j$ 列就是 $-I$。因此可以看出来，$A$ 只和相对位姿有关，在整个优化过程中都是固定的。

矩阵 $\Phi$ 是一个 $3m \times 3m$ 的对角阵，主对角线上每个元素就是第 $k$ 个相对旋转的权重，也就是 $\phi_{ij}$的值。注意每一对相对旋转是有三个权重值的，所以最终权重矩阵才是 $3m \times 3m$ 的。

$\Delta \Omega_{\delta}$ 是 $3m\times 1$ 的列向量，代表的用轴角表示的相对旋转和绝对旋转之间的差异，也就是 $\omega(\Delta R_{ji})=\omega( R_j^{-1}R_{ji}R_i)$

每次迭代完成后，都要重新计算 $\Phi 和 \Delta \Omega_{\delta}$。但由于这个方法不能保证收敛到全局最优，所以需要给定一个初始值，初始值就是使用基于1-范数的旋转平均得到的。也就是令 $\Omega_{\mathcal V}=\arg \min \left \| A\Omega_{\mathcal V}+\Delta \Omega_{\delta} \right \|$,这样就算是一次1-范数的迭代，迭代5次就终止，得到一个初始的全局旋转。然后在使用上面那个复杂的带权重的式子进行更准确的更新。

# 平移平均

使用 $R_{iw},t_{iw}$ 代表从世界坐标系到第 $i$ 个相机位置的变换，那么根据相对变换的定义可以得到
$$
\left\{
\begin{array}{c}
P_w=R_{wi}P_i+t_{wi} \\
P_w=R_{wj}P_j+t_{wj}
\end{array}
\right. \quad \Longrightarrow 
R_{wi}P_i+t_{wi} = R_{wj}P_j+t_{wj} \quad \Longrightarrow 
P_i=R_{iw}R_{wj}P_j+R_{iw}(t_{wj}-t_{wi})
$$
由此可以得到 $t_{ij}=R_{iw}(t_{wj}-t_{wi})$ ，其实就是上面两视图几何里的那个公式 $t_{12}=R_{1w}(t_{w2}-t_{w1})$

进而得到了 
$$
\frac{t_{wj}-t_{wi}}{\left \|t_{wj}-t_{wi}\right \|_2}=R_{wi}\hat{t}_{ij} \quad \Longrightarrow \quad \frac{t_j-t_i}{\left \| t_j-t_i \right \|_2}=R_i\hat{t}_{ij}
$$
这个公式就是平移平均里最常见的公式。其中的 $\hat{t}_{ij}$ 代表单位向量。

## BATA (Baseline Desensitizing in Translation Averaging - CVPR 2018)

作者用 $v_{ij}= R_i\hat{t}_{ij}$ ，优化目标是 $t_j-t_i$ 和 $v_{ij}$ 之间的夹角 $\theta_{ij}$ ，优化函数的形式为
$$
\begin{array}{cc}
&\min \sum_{ij}\rho\left(\left \| (t_j-t_i)d_{ij}-v_{ij} \right \|_2\right) \\
s.t.& \sum t_i=0, \ \sum_{ij} \left \langle t_j-t_i,v_{ij} \right \rangle =1 \\
& d_{ij}>0
\end{array}
$$
其中 $\rho(*)$ 是一个鲁棒函数，用来处理外点的。 

可以看出，当 $t_j-t_i$ 和 $v_{ij}$ 方向相同（小于90度）的时候，$d_{ij}$ 会倾向于让 $(t_j-t_i)d_{ij}$ 等于 $v_{ij}$ 在$t_j-t_i$方向上的投影。又因为 $v_{ij}$ 是单位向量，因此这种情况下他们之间的残差就是 $\sin \theta_{ij}$ 。

当 $t_j-t_i$ 和 $v_{ij}$ 方向相反（大于90度）的时候，这种情况很明显就是错误的，但是如果不对 $d_{ij}$ 做出限制，那么当它小于零的时候，依然可以让目标函数下降。为了避免这种情况，就要求它永远为正。

所以这个优化目标可以写的更简单一些
$$
\left \| (t_j-t_i)d_{ij}-v_{ij} \right \|_2=h(\theta_{ij})=
\left \{
\begin{array}{cc}\sin \theta_{ij},&\theta_{ij}\leq90^\circ  \\1,&\theta_{ij}>90^\circ \end{array}
\right .
$$
为了求解这个优化函数，作者使用了一个 *Robust Rotation-Assisted IRLS* 方法。这个方法使用的鲁棒核函数是柯西核，也就是
$$
\rho(\varepsilon)=\log\left( 1+\frac{\varepsilon^2}{\alpha^2}\right) \\
\phi(\varepsilon)=\frac{\alpha^2}{\alpha^2+\varepsilon^2} \\
\varepsilon = \sqrt{\left \| (t_j-t_i)d_{ij}-v_{ij} \right \|_2^2+\beta\left \| R_i^TR_j-R_{ij} \right \|_2^2}
$$
这里的 $\phi(\varepsilon)$ 就是每次迭代之后的权重设置。每次的残差不仅和相机的平移有关，还和相机的旋转有关，所以才是 *Rotation-Assisted*。因为旋转平均会比平移平均更稳定，更准确。

## 基于无穷范数的平移平均

这里介绍的方法是openMVG里所使用的方法，也就是*Global Fusion of Relative Motion - ICCV 2013* 对应的旋转平均方法，是论文中的公式(9).

论文中的目标函数是
$$
\begin{array}{c}
\min &\gamma  \\
s.t. & |t_j-R_{ij}t_i-\lambda_\tau t_{ij}| \le \gamma \\
& t_1=(0,0,0)^T \quad \lambda_\tau > c \\
& \gamma>0
\end{array}
$$
这里其实就是最小化$t_j-R_{ij}t_i-\lambda_\tau t_{ij}$ 的[无穷范数](#向量范数)。而且为了更加鲁棒，并不是每一个相对平移都有一个尺度，而是在每个triplet内部的三个相对平移有相同的尺度。

这个最小化的问题可以使用线性规划求解。线性规划的一般形式为
$$
\begin{array}{c}
\min& \mathbf {c}^T \mathbf{x} \\
s.t. &A_1\mathbf x \le b_1 \\
& A_2\mathbf x \ge b_2 \\
& A_3\mathbf x = b_3 \\
& \mathbf x_1 \le \mathbf x \le \mathbf x_2
\end{array}
$$
这里的 $\mathbf x$ 就是未知变量，$c^T\mathbf x$ 是它的线性函数，因此称为线性规划。在上面的目标函数里，未知量是 $t_i,\lambda_\tau,\gamma$，因此需要把约束改为
$$
\left \{
\begin{array}{c}
t_j-R_{ij}t_i-\lambda_\tau t_{ij} \le \gamma \\
t_j-R_{ij}t_i-\lambda_\tau t_{ij} \ge -\gamma
\end{array}
\right. \quad \Longrightarrow \quad
\left \{
\begin{array}{c}
t_j-R_{ij}t_i-\lambda_\tau t_{ij}- \gamma \le 0 \\
t_j-R_{ij}t_i-\lambda_\tau t_{ij}+\gamma \ge 0
\end{array}
\right.
$$
那么一个带绝对值的约束就变成了两个不带绝对值的约束，而需要同时对 $x\ y\ z$ 三个轴进行约束，因此每一对图像匹配会提供六个约束。对应的矩阵 $A, \mathbf x , b, c$ 的形式为
$$
A_1=\begin{bmatrix}
\dots & -R_{ij} & \dots & I_{3\times3} &\dots & -t_{ij} & \dots &-1 
\end{bmatrix}_{m\times n}\\
A_2=\begin{bmatrix}
\dots & -R_{ij} & \dots & I_{3\times3} &\dots & -t_{ij} & \dots &+1 
\end{bmatrix}_{m\times n}\\
b_1=b_2=0_{m\times1} \\
\mathbf x =[t_1\ t_2\  t_3 \ \dots\ \lambda_1 \ \lambda_2 \ \dots\ \gamma ]_{n\times1}\\
\mathbf c=[0 \ 0 \ 0 \ \dots \ 1]_{n\times1}\\
$$
这里的 $c$ 的前 $n-1$ 个数字都是0，只有最后一个是1

求解这个线性规划使用了 *[Clp求解器](https://github.com/coin-or/Clp)*。这个求解器在使用的时候必须把所有约束都转化为 $\le$ 的约束，因此对于 $A_2\mathbf x \ge b_2$ 需要改变成 $-A_2\mathbf x \le -b_2$; 对于 $A_3\mathbf x = b_3$ 需要改成 $A_3\mathbf x \le b_3 以及 -A_3\mathbf x \le -b_3$

## 基于二范数的旋转平均

这个方法是受到 *Robust Camera Location Estimation by Convex Programming - CVPR 2015* 这篇文章启发而来的。同样使用了 IRLS方法进行求解。 

这个方法最小化的是 $t_j-R_{ij}t_i-\lambda_{ij} t_{ij}$  ，也就是说目标函数可以写为
$$
\min \sum_{ij} w_{ij}\left \| t_j-R_{ij}t_i-\lambda_{ij}t_{ij}\right \|_2^2 \\
s.t. \quad \lambda_{ij}>c
$$
这里的 $t_i$ 代表 $t_{iw}$ 是从世界到相机 $i$ 的平移，$R_{ij},t_{ij}$ 是从相机 $i$ 到相机 $j$ 的相对变换。按照我的习惯应该写成 $R_{ji},t_{ji}$，不过为了好看就写成这样吧。

可以看出，这是一个基于二范数的优化，因此对噪声非常敏感，因此需要设置权重，给与外点更低的权重，使其不影响整体。权重的函数为
$$
w_{ij}= \left( \left \| t_j-R_{ij}t_i-\lambda_{ij}t_{ij}\right \|_2^2 + \delta \right )^{-1/2}
$$
这里的 $\delta$ 是一个很小的常数，设置为 0.01。

虽然使用加权的方法能令目标函数对外点具有一定的鲁棒性，但依然会受到噪声影响。而且这里的尺度也是不确定的，所以这个方法只适合在已知尺度的情况下进行求解。经过实验发现，只要给定了尺度，这个方法就能得到最好的效果。而确定尺度则需要其他手段，比如激光雷达。

# Multiple-View Stereo (MVS)

## 传播时近邻像素深度插值

基于Patch-Match 的MVS中最重要的就是进行传播深度值和法向量。假设当前点为 $x_0=(u_0,v_0)^T$ ，它的邻域像素为 $x_1=(u_1,v_1)^T$.在传播过程中，要把邻域像素的深度和法向量赋给当前像素，然后计算NCC，得到评分。最简单的方法就是直接把邻域的深度和法向量拿过来使用，这种方法虽然简单，但效果不是很好，产生的深度不够平滑。

另一种方式则是使用平面插值的方式。在 $x_1$ 处以深度 $d_1$ 和法向量  $\mathbf{n}$ 可以得到一个平面 $\pi$，这个平面和射线 $Ox_0$ 相交于一点 $P$ ，那么 $P$ 的深度就是当前点 $x_0$ 的深度，以这个深度进行NCC计算往往会得到更好的结果。以下为公式推导。

假设 $x_1$ 对应的三维点为 $P_1=d_1K^{-1}x_1$ ，由于 $P,P_1$ 都位于平面 $\pi$ 上，那么有
$$
\mathbf n^T(P-P_1)=0 \\
\mathbf n^T(dK^{-1}x_0-d_1K^{-1}x_1)=0 \\
\mathbf n^TK^{-1}(dx_0-d_1x_1)=0 \\
\begin{bmatrix}n_x & n_y &n_z \end{bmatrix}
\begin{bmatrix}1/f_x & 0 &-c_x/f_x \\ 0 & 1/f_y & -c_y/f_y \\ 0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}du_0-d_1u_1 \\ dv_0-d_1v_1 \\d-d_1 \end{bmatrix}
=0 \\
\begin{bmatrix}\frac{n_x}{f_x} & \frac{n_y}{f_y} & -c_x\frac{n_x}{f_x}-c_y\frac{n_y}{f_y}+n_z\end{bmatrix}
\begin{bmatrix}du_0-d_1u_1 \\ dv_0-d_1v_1 \\d-d_1 \end{bmatrix}
=0 \\
d=d_1\frac{\frac{n_x}{f_x}(u_1-c_x)+\frac{n_y}{f_y}(v_1-c_y)+n_z}{\frac{n_x}{f_x}(u_0-c_x)+\frac{n_y}{f_y}(v_0-c_y)+n_z}
$$
通过这种方法从近邻像素的深度 $d_1$ 插值得到当前像素的深度 $d$

### 简化计算

上述方法在某些情况下是有冗余的，可以简化一些计算过程，提升计算速度。用 $x_0 = (u_0-c_x)/f_x$ , $y_0 = (v_0-c_y)/f_y$ , $x_1 = (u_1-c_x)/f_x$ , $y_1 = (v_1-c_y)/f_y$ 来简化符号，上述过程可以写为
$$
d(n_xx_0+n_yy_0+n_z)=d_1(n_xx_1+n_yy_1+n_z) \\
\mathbf n^T \begin{bmatrix}dx_0\\dy_0\\d \end{bmatrix}=\mathbf n^T \begin{bmatrix}d_1x_1\\d_1y_1\\d_1 \end{bmatrix}
$$
这表明以原点为起点，$\mathbf{P,P_1}$ 为终点的两个向量在平面的法向量方向上的投影相等。

那么如果当前两个像素点的 $u$ 坐标相等，那么只需要在YOZ平面上进行上述计算，省略X轴，也就是说
$$
d(n_yy_0+n_z)=d_1(n_yy_1+n_z) \\
d=\frac{d_1(n_yy_1+n_z)}{n_yy_0+n_z}
$$
**以上就是OpenMVS中的计算方法(位于函数`InterpolatePixel`)，但是我有一些疑问，为什么在YOZ平面上计算，这种计算结果感觉不正确**

# 组合数计算

所谓的组合数也就是二项式系数 $C_n^k$ ，也就是排列组合中从 $n$ 个数字中选出 $k$ 个，与顺序无关。

这个主要用在ACRANSAC中的NFA计算过程中。根据组合数的公式可以得到
$$
\left \{
\begin{array}{rl}
C_n^k&=\frac{n!}{(n-k)!k!} \\
C_n^{k+1}&=\frac{n!}{(n-k-1)!(k+1)!} \\
C_{n+1}^{k}&=\frac{(n+1)!}{(n+1-k)!k!}
\end{array}
\right . 
\Longrightarrow
\left \{
\begin{array}{rl}
C_n^{k+1}&=\frac{(n-k)}{(n-k)!}\frac{n!}{k!(k+1)}=C_n^k\frac{n-k}{k+1} \\
C_{n+1}^{k}&=\frac{n!(n+1)}{(n-k)!(n+1-k)k!}=C_n^k\frac{n+1}{n+1-k}
\end{array}
\right .
$$
取对数后可以得到
$$
\log C_n^{k+1}=\log C_n^k + \log (n-k) - \log (k+1) \\
\log C_{n+1}^{k}= \log C_n^k + \log (n+1) - \log{n+1-k}
$$
